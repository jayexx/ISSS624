---
title: "Hands-on_Ex2-3"
author: "J X Low"
---

## Overview

In this hands-on exercise, I learn how to compute Global and Local Measure of Spatial Autocorrelation (GLSA) in R, using **sf** (*for import*), **readr** (*for import*), **dplyr** (*for relational join*), **tmap** (*for output visualisation analysis*), and **spdep** (*for the areas below*) packages.

-   compute Global Spatial Autocorrelation (GSA) statistics by using appropriate functions of spdep package,
    -   plot Moran scatterplot,
    -   compute and plot spatial correlogram using appropriate function of spdep package.
-   compute Local Indicator of Spatial Association (LISA) statistics for detecting clusters and outliers by using appropriate functions spdep package;
-   compute Getis-Ord's Gi-statistics for detecting hot spot or/and cold spot area by using appropriate functions of spdep package

## Getting Started

### The analytical question

In spatial policy, one of the main development objective of the local government and planners is to ensure equal distribution of development in the province. Our task in this study, hence, is to apply appropriate spatial statistical methods to discover if development are even distributed geographically. If the answer is No. Then, our next question will be “is there sign of spatial clustering?”. And, if the answer for this question is yes, then our next question will be “where are these clusters?”

In this case study, we are interested to examine the spatial pattern of a selected development indicator (i.e. GDP per capita) of [Hunan Provice, People Republic of China](https://en.wikipedia.org/wiki/Hunan).

### Datasets

Data set consists of:

- Hunan province administrative boundary layer at county level. This is a geospatial data set in ESRI shapefile format.
- Hunan_2012.csv: This csv file contains selected Hunan’s local development indicators in 2012.

### Loading packages

The code chunk below installs and loads [spdep](https://cran.r-project.org/web/packages/spdep/spdep.pdf) [sf](https://cran.r-project.org/web/packages/sf/sf.pdf), [tmap](https://cran.r-project.org/web/packages/tmap/tmap.pdf) and tidyverse packages into R environment

```{r}
pacman:: p_load(dplyr, readr, tmap, sf, tidyverse, spdep, knitr)
```

## Importing Data

Raw data files were obtained for Hunan from e-learn.

### Import shapefile into r environment

```{r}
hunan <- st_read(dsn = "data/geospatial", 
                 layer = "Hunan")
```

### Importing Attribute Data (csv file)

```{r}
hunan2012 <- read_csv("data/aspatial/Hunan_2012.csv", show_col_types = FALSE)
```

### Data Preparation (relational join)

Update the attribute table of Hunan's Spatial Polygons DataFrame with the attribute fields of hunan2012 DataFrame by using left_join() of dplyr package, with the following code chunk

```{R}
hunan <- left_join(hunan,hunan2012)%>%
  select(1:4, 7, 15)
```

### Visualising Regional Development Indicator

Prepare a basemap and a choropleth map showing the distribution of GDPPC 2012 by using qtm() of tmap package

```{R}
equal <- tm_shape(hunan) +
  tm_fill("GDPPC",
          n = 5,
          style = "equal") +
  tm_borders(alpha = 0.5) +
  tm_layout(main.title = "Equal interval classification")

quantile <- tm_shape(hunan) +
  tm_fill("GDPPC",
          n = 5,
          style = "quantile") +
  tm_borders(alpha = 0.5) +
  tm_layout(main.title = "Equal quantile classification")

tmap_arrange(equal, 
             quantile, 
             asp=1, 
             ncol=2)
```

## Global Spatial Autocorrelation

### Computing Contiguity Spatial Weights

1st, construct a spatial weights of the study area. The spatial weights is used to define the neighbourhood relationships between the geographical units (i.e. county) in the study area.

poly2nb() of spdep package is used to compute contiguity weight matrices for the study area. This function builds a neighbours list based on regions with contiguous boundaries. Based on the documentation, a “queen” argument that takes TRUE or FALSE as options will be able to pass. If this argument is not specified, the default is set to TRUE, that is, if queen = FALSE is not specified this function will return a list of 1st order neighbours using the Queen criteria.

More specifically, compute Queen contiguity weight matrix as follows.

```{R}
wm_q <- poly2nb(hunan, 
                queen=TRUE)
summary(wm_q)
```
Summary report above shows 88 area units in Hunan, with the most connected area unit having 11 neighbours, and only 2 area units with only 1 neighbour.

### Row-standardised weights matrix

Need to assign weights to each neighboring polygon. Each neighboring polygon will be assigned equal weight (style=“W”). This is done by assigning the fraction 1/(#ofneighbors) to each neighboring county then summing the weighted income values. While this is the most intuitive way to summarise the neighbors’ values, one drawback is that polygons along the edges of the study area will base their lagged values on fewer polygons, thus potentially over- or under-estimating the true nature of the spatial autocorrelation in the data. For this example, we’ll stick with the style=“W” option for simplicity’s sake but note that other more robust options are available, notably style=“B”.

```{R}
rswm_q <- nb2listw(wm_q, 
                   style="W", 
                   zero.policy = TRUE)
rswm_q
```

The input of nb2listw() must be an object of class nb. The syntax of the function has two major arguments, namely style and zero.poly.

- style can take values “W”, “B”, “C”, “U”, “minmax” and “S”. B is the basic binary coding, W is row standardised (sums over all links to n), C is globally standardised (sums over all links to n), U is equal to C divided by the number of neighbours (sums over all links to unity), while S is the variance-stabilizing coding scheme proposed by Tiefelsdorf et al. 1999, p. 167-168 (sums over all links to n).

- If zero policy is set to TRUE, weights vectors of zero length are inserted for regions without neighbour in the neighbours list. These will in turn generate lag values of zero, equivalent to the sum of products of the zero row t(rep(0, length=length(neighbours))) %*% x, for arbitrary numerical vector x of length length(neighbours). The spatially lagged value of x for the zero-neighbour region will then be zero, which may (or may not) be a sensible choice.

### Global Spatial Autocorrelation: Moran’s I

Code chunk below performs Moran’s I statistical testing using moran.test() of spdep.

```{R}
moran.test(hunan$GDPPC, 
           listw=rswm_q, 
           zero.policy = TRUE, 
           na.action=na.omit)
```
Question: What statistical conclusion can you draw from the output above?

Answer: Since p-value < 5%, reject the null hypothesis with 95% confidence, and hence it is statistically significant  that the value is greater.

#### Computing Monte Carlo Moran’s I

The code chunk below performs permutation test for Moran’s I statistic by using moran.mc() of spdep. A total of 1000 simulation will be performed.

```{R}
set.seed(1234)
bperm= moran.mc(hunan$GDPPC, 
                listw=rswm_q, 
                nsim=999, 
                zero.policy = TRUE, 
                na.action=na.omit)
bperm
```

Question: What statistical conclustion can you draw from the output above?

Answer: Based on the simulation, a similar conclusion can be drawn with p-value <5%, that it is statistically significant  that the value is greater.

#### Visualising Monte Carlo Moran’s I

Examine the simulated Moran’s I test statistics in greater detail by plotting the distribution of the statistical values as a histogram by using the code chunk below, using hist() and abline() of R Graphics.

```{R}
mean(bperm$res[1:999])
```

```{R}
var(bperm$res[1:999])
```

```{R}
summary(bperm$res[1:999])
```

```{R}
hist(bperm$res, 
     freq=TRUE, 
     breaks=20, 
     xlab="Simulated Moran's I")
abline(v=0, 
       col="red") 
```
Question: What statistical observation can you draw from the output above?

Challenge: Instead of using Base Graph to plot the values, plot the values by using ggplot2 package.

### Global Spatial Autocorrelation: Geary’s

#### Geary’s C test

Geary’s C test for spatial autocorrelation by using geary.test() of spdep

```{R}
geary.test(hunan$GDPPC, listw=rswm_q)
```

#### Computing Monte Carlo Geary’s C

Permutation test for Geary’s C statistic by using geary.mc() of spdep

```{R}
set.seed(1234)
bperm=geary.mc(hunan$GDPPC, 
               listw=rswm_q, 
               nsim=999)
bperm
```
Question: What statistical conclusion can you draw from the output above?

Answer: Since p-value < 5%, reject the null hypothesis with 95% confidence, and hence it is statistically significant  that the value is greater.

#### Visualising the Monte Carlo Geary’s C

Plot a histogram to reveal the distribution of the simulated values by using the code chunk below.

```{R}
mean(bperm$res[1:999])
```

```{R}
var(bperm$res[1:999])
```

```{R}
summary(bperm$res[1:999])
```

```{R}
hist(bperm$res, freq=TRUE, breaks=20, xlab="Simulated Geary c")
abline(v=1, col="red") 
```
Question: What statistical observation can you draw from the output?

## Spatial Correlogram

Spatial correlograms are great to examine patterns of spatial autocorrelation in your data or model residuals. They show how correlated are pairs of spatial observations when you increase the distance (lag) between them - they are plots of some index of autocorrelation (Moran’s I or Geary’s c) against distance.Although correlograms are not as fundamental as variograms (a keystone concept of geostatistics), they are very useful as an exploratory and descriptive tool. For this purpose they actually provide richer information than variograms.

### Compute Moran’s I correlogram

Use sp.correlogram() of spdep package to compute a 6-lag spatial correlogram of GDPPC. The global spatial autocorrelation used in Moran’s I. The plot() of base Graph is then used to plot the output.

```{R}
MI_corr <- sp.correlogram(wm_q, 
                          hunan$GDPPC, 
                          order=6, 
                          method="I", 
                          style="W")
plot(MI_corr)
```
By plotting the output might not allow us to provide complete interpretation. This is because not all autocorrelation values are statistically significant. 

Hence, it is important for us to examine the full analysis report by printing out the analysis results as in the code chunk below.

```{R}
print(MI_corr)
```
Question: What statistical observation can you draw from the plot above?

### Compute Geary’s C correlogram and plot

Use sp.correlogram() of spdep package to compute a 6-lag spatial correlogram of GDPPC. The global spatial autocorrelation used in Geary’s C. The plot() of base Graph is then used to plot the output.

```{R}
GC_corr <- sp.correlogram(wm_q, 
                          hunan$GDPPC, 
                          order=6, 
                          method="C", 
                          style="W")
plot(GC_corr)
```

Similar to before, print the analysis report using the code chunk below.

```{R}
print(GC_corr)
```

## Cluster and Outlier Analysis

Local Indicators of Spatial Association or LISA are statistics that evaluate the existence of clusters in the spatial arrangement of a given variable. For instance if we are studying cancer rates among census tracts in a given city local clusters in the rates mean that there are areas that have higher or lower rates than is to be expected by chance alone; that is, the values occurring are above or below those of a random distribution in space.

In this section, you will learn how to apply appropriate Local Indicators for Spatial Association (LISA), especially local Moran’I to detect cluster and/or outlier from GDP per capita 2012 of Hunan Province, PRC.

### Computing local Moran’s I

Compute local Moran’s I using the localmoran() function of spdep. It computes Ii values, given a set of zi values and a listw object providing neighbour weighting information for the polygon associated with the zi values.

Compute local Moran’s I of GDPPC2012 at the county level as follows.

```{R}
fips <- order(hunan$County)
localMI <- localmoran(hunan$GDPPC, rswm_q)
head(localMI)
```

localmoran() function returns a matrix of values whose columns are:

- Ii: the local Moran’s I statistics
- E.Ii: the expectation of local moran statistic under the randomisation hypothesis
- Var.Ii: the variance of local moran statistic under the randomisation hypothesis
- Z.Ii:the standard deviate of local moran statistic
- Pr(): the p-value of local moran statistic

The code chunk below list the content of the local Moran matrix derived by using printCoefmat().

```{R}
printCoefmat(data.frame(
  localMI[fips,], 
  row.names=hunan$County[fips]),
  check.names=FALSE)
```

#### Mapping the local Moran’s I

Before mapping the local Moran’s I map, it is wise to append the local Moran’s I dataframe (i.e. localMI) onto hunan SpatialPolygonDataFrame using the code chunks below. The out SpatialPolygonDataFrame is called hunan.localMI.

```{R}
hunan.localMI <- cbind(hunan,localMI) %>%
  rename(Pr.Ii = Pr.z....E.Ii..)
```

#### Mapping local Moran’s I values

Plot the local Moran’s I values Using choropleth mapping functions of tmap package with the code chunk below

```{R}
tm_shape(hunan.localMI) +
  tm_fill(col = "Ii", 
          style = "pretty",
          palette = "RdBu",
          title = "local moran statistics") +
  tm_borders(alpha = 0.5)
```

#### Mapping local Moran’s I p-values

The choropleth shows there is evidence for both positive and negative Ii values. However, it is useful to consider the p-values for each of these values, as considered above.

The code chunks below produce a choropleth map of Moran’s I p-values by using functions of tmap package.

```{R}
tm_shape(hunan.localMI) +
  tm_fill(col = "Pr.Ii", 
          breaks=c(-Inf, 0.001, 0.01, 0.05, 0.1, Inf),
          palette="-Blues", 
          title = "local Moran's I p-values") +
  tm_borders(alpha = 0.5)
```

#### Mapping both local Moran’s I values and p-values
For effective interpretation, it is better to plot both the local Moran’s I values map and its corresponding p-values map next to each other.

The code chunk below will be used to create such visualisation.

```{R}
localMI.map <- tm_shape(hunan.localMI) +
  tm_fill(col = "Ii", 
          style = "pretty", 
          title = "local moran statistics") +
  tm_borders(alpha = 0.5)

pvalue.map <- tm_shape(hunan.localMI) +
  tm_fill(col = "Pr.Ii", 
          breaks=c(-Inf, 0.001, 0.01, 0.05, 0.1, Inf),
          palette="-Blues", 
          title = "local Moran's I p-values") +
  tm_borders(alpha = 0.5)

tmap_arrange(localMI.map, pvalue.map, asp=1, ncol=2)
```

## Creating a LISA Cluster Map

The LISA Cluster Map shows the significant locations color coded by type of spatial autocorrelation. The 1st step before generating the LISA cluster map is to plot the Moran scatterplot.

### Plotting Moran scatterplot

The Moran scatterplot is an illustration of the relationship between the values of the chosen attribute at each location and the average value of the same attribute at neighboring locations.

The code chunk below plots the Moran scatterplot of GDPPC 2012 by using moran.plot() of spdep.

```{R}
nci <- moran.plot(hunan$GDPPC, rswm_q,
                  labels=as.character(hunan$County), 
                  xlab="GDPPC 2012", 
                  ylab="Spatially Lag GDPPC 2012")
```
Notice that the plot is split in 4 quadrants. The top right corner belongs to areas that have high GDPPC and are surrounded by other areas that have the average level of GDPPC. This are the high-high locations in the lesson slide.

### Plotting Moran scatterplot with standardised variable

1st, Use scale() to centers and scales the variable. Centering is done by subtracting the mean (omitting NAs) from the corresponding columns, and scaling is done by dividing the (centered) variable by their standard deviations.

```{R}
hunan$Z.GDPPC <- scale(hunan$GDPPC) %>% 
  as.vector 
```

The as.vector() added to the end is to make sure that the data type we get out of this is a vector, that map neatly into out dataframe.

Now, we are ready to plot the Moran scatterplot again by using the code chunk below.

```{R}
nci2 <- moran.plot(hunan$Z.GDPPC, rswm_q,
                   labels=as.character(hunan$County),
                   xlab="z-GDPPC 2012", 
                   ylab="Spatially Lag z-GDPPC 2012")
```

### Preparing LISA map classes

The code chunks below show the steps to prepare a LISA cluster map.

```{R}
quadrant <- vector(mode="numeric",length=nrow(localMI))
```

Derive the spatially lagged variable of interest (i.e. GDPPC) and center the spatially lagged variable around its mean.

```{R}
hunan$lag_GDPPC <- lag.listw(rswm_q, hunan$GDPPC)
DV <- hunan$lag_GDPPC - mean(hunan$lag_GDPPC)
```

Center the local Moran’s around the mean

```{R}
LM_I <- localMI[,1] - mean(localMI[,1]) 
```

Set a statistical significance lvl for the local Moran.

```{R}
signif <- 0.05
```

4 command lines define the low-low (1), low-high (2), high-low (3) and high-high (4) categories as follows.

```{R}
quadrant[DV <0 & LM_I>0] <- 1
quadrant[DV >0 & LM_I<0] <- 2
quadrant[DV <0 & LM_I<0] <- 3  
quadrant[DV >0 & LM_I>0] <- 4 
```

Place non-significant Moran in the category 0

```{R}
quadrant[localMI[,5]>signif] <- 0
```
If preferred, may combine all the above steps into one single code chunk

### Plotting LISA map

Build the LISA map by using the code chunks below.

```{R}
hunan.localMI$quadrant <- quadrant
colors <- c("#ffffff", "#2c7bb6", "#abd9e9", "#fdae61", "#d7191c")
clusters <- c("insignificant", "low-low", "low-high", "high-low", "high-high")

tm_shape(hunan.localMI) +
  tm_fill(col = "quadrant", 
          style = "cat", 
          palette = colors[c(sort(unique(quadrant)))+1], 
          labels = clusters[c(sort(unique(quadrant)))+1],
          popup.vars = c("")) +
  tm_view(set.zoom.limits = c(11,17)) +
  tm_borders(alpha=0.5)
```

For effective interpretation, it is better to plot both the local Moran’s I values map and its corresponding p-values map next to each other.

The code chunk below will be used to create such visualisation.

```{R}
gdppc <- qtm(hunan, "GDPPC")

hunan.localMI$quadrant <- quadrant
colors <- c("#ffffff", "#2c7bb6", "#abd9e9", "#fdae61", "#d7191c")
clusters <- c("insignificant", "low-low", "low-high", "high-low", "high-high")

LISAmap <- tm_shape(hunan.localMI) +
  tm_fill(col = "quadrant", 
          style = "cat", 
          palette = colors[c(sort(unique(quadrant)))+1], 
          labels = clusters[c(sort(unique(quadrant)))+1],
          popup.vars = c("")) +
  tm_view(set.zoom.limits = c(11,17)) +
  tm_borders(alpha=0.5)

tmap_arrange(gdppc, LISAmap, 
             asp=1, ncol=2)
```

We can also include the local Moran’s I map and p-value map for easy comparison.

Question: What statistical observations can you draw from the LISA map above?

## Hot Spot and Cold Spot Area Analysis

Beside detecting cluster and outliers, localised spatial statistics can be also used to detect hot spot and/or cold spot areas.

The term ‘hot spot’ has been used generically across disciplines to describe a region or value that is higher relative to its surroundings (Lepers et al 2005, Aben et al 2012, Isobe et al 2015).

An alternative spatial statistics to detect spatial anomalies is the Getis and Ord’s G-statistics (Getis and Ord, 1972; Ord and Getis, 1995). It looks at neighbours within a defined proximity to identify where either high or low values cluster spatially. Here, statistically significant hot-spots are recognised as areas of high values where other areas within a neighbourhood range also share high values too.

The analysis consists of three steps in the following sub sections

### Deriving distance-based weight matrix

Define a new set of neighbours. Whist the spatial autocorrelation considered units which shared borders, for Getis-Ord we are defining neighbours based on distance.

There are two type of distance-based proximity matrix, they are:

- fixed distance weight matrix; and
- adaptive distance weight matrix.

#### Deriving the centroid

We will need points to associate with each polygon before we can make our connectivity graph. It will be a little more complicated than just running st_centroid() on the sf object: us.bound. We need the coordinates in a separate data frame for this to work. To do this we will use a mapping function. The mapping function applies a given function to each element of a vector and returns a vector of the same length. Our input vector will be the geometry column of us.bound. Our function will be st_centroid(). We will be using map_dbl variation of map from the purrr package. For more documentation, check out map documentation

To get our longitude values we map the st_centroid() function over the geometry column of us.bound and access the longitude value through double bracket notation [[]] and 1. This allows us to get only the longitude, which is the first value in each centroid.

```{R}
longitude <- map_dbl(hunan$geometry, ~st_centroid(.x)[[1]])
```

Same for latitude except that the second value per each centroid is used with [[2]].

```{R}
latitude <- map_dbl(hunan$geometry, ~st_centroid(.x)[[2]])
```

Use cbind to put longitude and latitude into the same object

```{R}
coords <- cbind(longitude, latitude)
```

#### Determine the cut-off distance

Determine the Distance Band Upper Limit with the code chunks below, based on the following steps.

-   Obtain matrix with the indices of points belonging to the set of the k nearest neighbours of each other by using knearneigh() of spdep.
-   Using knn2nb(), convert the resultant object returned by knearneigh() into a neighbours list, of class 'nb', with a list of integer vectors containing neighbour region number ids
-   Using nbdists() of spdep, find the length of neighbour relationship edges. The function returns in the units of the coordinates if the coordinates are projected, or else in km.
-   Using unlist(), remove the list structure of the returned object.

```{R}
#coords <- coordinates(hunan)
k1 <- knn2nb(knearneigh(coords))
k1dists <- unlist(nbdists(k1, coords, longlat = TRUE))
summary(k1dists)
```

Summary above shows that the largest 1st nearest neighbour distance is 61.79 km, so using this as the upper threshold gives certainty that all units will have at least 1 neighbour

### Computing fixed distance weight matrix

```{R}
wm_d62 <- dnearneigh(coords, 0, 62, longlat = TRUE)
wm_d62
```

Use nb2listw() to convert the nb object into spatial weights object.

```{R}
wm62_lw <- nb2listw(wm_d62, style = 'B')
summary(wm62_lw)
```

### Computing adaptive distance weight matrix

For fixed distance weight matrix, more densely settled areas (usually urban areas) tend to have more neighbours and the less densely settled areas (usually rural counties) tend to have lesser neighbours. Having many neighbours means the influence of each neighbor on a given feature is distributed across a larger number of neighbors, which can help to reduce the impact of outliers and other anomalies in the data.

To control the number of neighbours directly using k-nearest neighbours, we can either accept asymmetric neighbours or impose symmetry with the following code chunk.

```{R}
knn <- knn2nb(knearneigh(coords, k=8))
knn
```

Use nb2listw() to convert the nb object into spatial weights object.

```{R}
knn_lw <- nb2listw(knn, style = 'B')
summary(knn_lw)
```

## Computing Gi statistics

### Gi statistics using fixed distance

```{R}
fips <- order(hunan$County)
gi.fixed <- localG(hunan$GDPPC, wm62_lw)
gi.fixed
```
The output of localG() is a vector of G or Gstar values, with attributes “gstari” set to TRUE or FALSE, “call” set to the function call, and class “localG”.

The Gi statistics is represented as a Z-score. Greater values represent a greater intensity of clustering and the direction (positive or negative) indicates high or low clusters.

Join the Gi values to their corresponding hunan sf data frame by using the code chunk below.

```{R}
hunan.gi <- cbind(hunan, as.matrix(gi.fixed)) %>%
  rename(gstat_fixed = as.matrix.gi.fixed.)
```
In fact, the code chunk above performs three tasks. First, it convert the output vector (i.e. gi.fixed) into r matrix object by using as.matrix(). Next, cbind() is used to join hunan@data and gi.fixed matrix to produce a new SpatialPolygonDataFrame called hunan.gi. Lastly, the field name of the gi values is renamed to gstat_fixed by using rename().

###  Mapping Gi values with fixed distance weights

The code chunk below shows the functions used to map the Gi values derived using fixed distance weight matrix.

```{R}
gdppc <- qtm(hunan, "GDPPC")

Gimap <-tm_shape(hunan.gi) +
  tm_fill(col = "gstat_fixed", 
          style = "pretty",
          palette="-RdBu",
          title = "local Gi") +
  tm_borders(alpha = 0.5)

tmap_arrange(gdppc, Gimap, asp=1, ncol=2)
```

Question: What statistical observation can you draw from the Gi map above?

### Gi statistics using adaptive distance

The code chunk below is used to compute the Gi values for GDPPC2012 by using an adaptive distance weight matrix (i.e knb_lw).

```{R}
fips <- order(hunan$County)
gi.adaptive <- localG(hunan$GDPPC, knn_lw)
hunan.gi <- cbind(hunan, as.matrix(gi.adaptive)) %>%
  rename(gstat_adaptive = as.matrix.gi.adaptive.)
```

### Mapping Gi values with adaptive distance weights

It is time to visualise the locations of hot spot and cold spot areas. Use the choropleth mapping functions of tmap package to map the Gi values.

The code chunk below shows the functions used to map the Gi values derived using fixed distance weight matrix.

```{R}
gdppc<- qtm(hunan, "GDPPC")

Gimap <- tm_shape(hunan.gi) + 
  tm_fill(col = "gstat_adaptive", 
          style = "pretty", 
          palette="-RdBu", 
          title = "local Gi") + 
  tm_borders(alpha = 0.5)

tmap_arrange(gdppc, 
             Gimap, 
             asp=1, 
             ncol=2)
```

Question: What statistical observation can you draw from the Gi map above?

